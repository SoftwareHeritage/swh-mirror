storage:
  cls: pipeline
  steps:
    - cls: tenacious
      error_rate_limit:
        # fail after 10 errors for 1000 operations
        errors: 10
        window_size: 1000
    - cls: remote
      url: http://storage:5002/
      max_retries: 5
      pool_connections: 100
      pool_maxsize: 200

journal_client:
  cls: kafka

  ####################
  # **TO BE MODIFIED**
  brokers:
    - <kafka1>
    - <...>
  # Note: if deploying graph replayer services per object types (or groups of
  # types), you should use differente consumer group ids, e.g.
  # '<test-user>-graph-replater-directory-01' for the service dedicated to
  # replaying only directories.
  group_id: <test-user>-graph-replayer-<object-types>-<x-change-me>
  sasl.username: <test-user>
  sasl.password: <password>
  ####################

  security.protocol: sasl_ssl
  sasl.mechanism: SCRAM-SHA-512
  session.timeout.ms: 600000
  max.poll.interval.ms: 3600000
  message.max.bytes: 1000000000
  privileged: true

replayer:
  error_reporter:
    # used to track objects that the replayer really failed at storing in the
    # storage
    host: redis
    port: 6379
    db: 0
